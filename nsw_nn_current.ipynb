{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Building AEMO's demand forecasting neural network from scratch\n",
    "- Based on AEMO's [Neural Network Documentation](https://aemo.com.au/-/media/files/pdf/so_fd_01__five_minute_electricity_demand_forecasting_neural_network_documentation.pdf)\n",
    "- The model predicts the logarithmic change in demand for the region\n",
    "- The input data, weights, and biases are based on the NSW neural network that is described in the documentation\n",
    "- The documentation appears to have combined the weights and biases together in the same table\n",
    "- The neural network is based on this tutorial [video](https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3) series and [book](https://nnfs.io/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Date  Demand\n",
       "0  1998-02-01 00:00:00    6010\n",
       "1  1998-02-01 00:05:00    5990\n",
       "2  1998-02-01 00:10:00    6000\n",
       "3  1998-02-01 00:15:00    5970\n",
       "4  1998-02-01 00:20:00    5960\n",
       "5  1998-02-01 00:25:00    5880\n",
       "6  1998-02-08 00:00:00    6250\n",
       "7  1998-02-08 00:05:00    6280\n",
       "8  1998-02-08 00:10:00    6180\n",
       "9  1998-02-08 00:15:00    6210\n",
       "10 1998-02-08 00:20:00    6160"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Demand</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1998-02-01 00:00:00</td>\n      <td>6010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1998-02-01 00:05:00</td>\n      <td>5990</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1998-02-01 00:10:00</td>\n      <td>6000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1998-02-01 00:15:00</td>\n      <td>5970</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1998-02-01 00:20:00</td>\n      <td>5960</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1998-02-01 00:25:00</td>\n      <td>5880</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1998-02-08 00:00:00</td>\n      <td>6250</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1998-02-08 00:05:00</td>\n      <td>6280</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1998-02-08 00:10:00</td>\n      <td>6180</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1998-02-08 00:15:00</td>\n      <td>6210</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1998-02-08 00:20:00</td>\n      <td>6160</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "nsw_df = pd.read_csv('data/nsw_example_data.csv', parse_dates=['Date'], dayfirst=True)\n",
    "nsw_df"
   ]
  },
  {
   "source": [
    "### Inputs\n",
    "- The neural network has 9 input values based on:\n",
    "    - The logarithmic changes in demand in the 4 dispatch intervals immediately before the interval the prediction is being run for\n",
    "    - The 5 dispatch intervals precisely a week before\n",
    "- AEMO has provided the pretrained weights and biases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.00333334,  0.00166806, -0.00501254, -0.00167645, -0.01351372,\n",
       "        0.00478852, -0.01605171,  0.00484262, -0.00808412])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "def gen_inputs(df):\n",
    "    '''\n",
    "    Generate the 9 input values to predict demand for the next 5 minute dispatch interval\n",
    "    '''\n",
    "    # the datetime of the next dispatch datetime\n",
    "    ddt = nsw_df['Date'].max() + timedelta(minutes=5)\n",
    "\n",
    "    dt11 = df[df['Date']==ddt - timedelta(days=7, minutes=25)]['Demand'].iloc[0]\n",
    "    dt10 = df[df['Date']==ddt - timedelta(days=7, minutes=20)]['Demand'].iloc[0]\n",
    "    dt9 = df[df['Date']==ddt - timedelta(days=7, minutes=15)]['Demand'].iloc[0]\n",
    "    dt8 = df[df['Date']==ddt - timedelta(days=7, minutes=10)]['Demand'].iloc[0]\n",
    "    dt7 = df[df['Date']==ddt - timedelta(days=7, minutes=5)]['Demand'].iloc[0]\n",
    "    dt6 = df[df['Date']==ddt - timedelta(days=7, minutes=0)]['Demand'].iloc[0]\n",
    "\n",
    "    dt5 = df[df['Date']==ddt - timedelta(days=0, minutes=25)]['Demand'].iloc[0]\n",
    "    dt4 = df[df['Date']==ddt - timedelta(days=0, minutes=20)]['Demand'].iloc[0]\n",
    "    dt3 = df[df['Date']==ddt - timedelta(days=0, minutes=15)]['Demand'].iloc[0]\n",
    "    dt2 = df[df['Date']==ddt - timedelta(days=0, minutes=10)]['Demand'].iloc[0]\n",
    "    dt1 = df[df['Date']==ddt - timedelta(days=0, minutes=5)]['Demand'].iloc[0]\n",
    "\n",
    "    X = np.array([\n",
    "        # 1 week before\n",
    "        np.log(dt10/dt11),\n",
    "        np.log(dt9/dt10),\n",
    "        np.log(dt8/dt9),\n",
    "        np.log(dt7/dt8),\n",
    "        np.log(dt6/dt7),\n",
    "        # 4 dispatch intervals before\n",
    "        np.log(dt4/dt5),\n",
    "        np.log(dt3/dt4),\n",
    "        np.log(dt2/dt3),\n",
    "        np.log(dt1/dt2),\n",
    "    ])\n",
    "\n",
    "    return X\n",
    "\n",
    "X = gen_inputs(nsw_df)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_weights = np.array([\n",
    "    [0.787908442,-3.03342919,-0.805006387,-2.24481232,-6.91548304,1.899275,1.67724099,3.34159312,2.33262311],\n",
    "    [-0.280762392,-1.28836905,-1.64200928,-2.93899286,-0.413204144,2.10931932,-0.0174202002,-0.498683481,1.10089596],\n",
    "    [-0.0541686846,-0.00341524871,0.662373364,0.409496988,2.02470863,-0.140064819,0.0654530737,0.0654530737,-1.07629121],\n",
    "    [-0.07762109,-0.161543795,0.344925654,1.99314546,0.843839487,0.648678667,0.752352854,1.15456333,0.839209192],\n",
    "]).T\n",
    "\n",
    "output_weights = np.array([0.171686888,-0.134112006, 1.06132145,1.9234954])\n",
    "\n",
    "layer_1_biases = np.array([-1.18083652,0.912479873,0.168973233,-1.92511602])\n",
    "output_biases = np.array([-0.766221613])"
   ]
  },
  {
   "source": [
    "## Neural network implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs=None, n_neurons=None, weights=None, biases=None):\n",
    "        if weights is None:\n",
    "            self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
    "            self.biases = np.zeros((1, n_neurons))\n",
    "        else:\n",
    "            self.weights = weights\n",
    "            self.biases = biases\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "class Activation_Sigmoid:\n",
    "    def forward(self, inputs):\n",
    "        self.output = 1 / (1 + np.exp(-inputs))"
   ]
  },
  {
   "source": [
    "## Define the model\n",
    "- 9 neurons in the input layer\n",
    "- 4 neurons in the hidden layer\n",
    "- 1 output neuron\n",
    "- Add the pretrained weights/biases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = Layer_Dense(9, 4, layer_1_weights, layer_1_biases)\n",
    "activation_1 = Activation_Sigmoid()\n",
    "\n",
    "output_layer = Layer_Dense(4, 1, output_weights, output_biases)\n",
    "activation_output = Activation_Sigmoid()"
   ]
  },
  {
   "source": [
    "## Neural network forward propagation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1.forward(X)\n",
    "activation_1.forward(layer_1.output)\n",
    "\n",
    "output_layer.forward(activation_1.output)\n",
    "activation_output.forward(output_layer.output)"
   ]
  },
  {
   "source": [
    "## Prediction\n",
    "- To get the predicted logarithmic change, multiply the output by 2 and minus 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.00572127])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "2 * activation_output.output - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}